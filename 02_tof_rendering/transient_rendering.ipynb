{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d619ac32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import drjit as dr\n",
    "import mitsuba as mi\n",
    "import numpy as np\n",
    "from scenes import cornell_box, cornell_box_steady_state\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML\n",
    "\n",
    "\n",
    "mi.set_variant('cuda_ad_rgb')\n",
    "\n",
    "import mitransient as mitr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "874ffffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianPulse:\n",
    "    \"\"\"\n",
    "    Normalized Gaussian pulse centered at t=0.\n",
    "\n",
    "    The pulse is defined as:\n",
    "        p(t) = (1 / (σ √(2π))) × exp(-t² / (2σ²))\n",
    "\n",
    "    where σ is the standard deviation (width_opl in optical path length units).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, width_opl: float):\n",
    "        \"\"\"\n",
    "        Initialize the Gaussian pulse.\n",
    "\n",
    "        Args:\n",
    "            width_opl: Standard deviation in optical path length units (meters)\n",
    "        \"\"\"\n",
    "        self.width_opl = width_opl\n",
    "        self.normalization = 1.0 / (self.width_opl * dr.sqrt(2 * dr.pi))\n",
    "\n",
    "    def eval(self, t: mi.Float) -> mi.Float:\n",
    "        \"\"\"\n",
    "        Evaluate the Gaussian at time offset t.\n",
    "\n",
    "        Args:\n",
    "            t: Time offset from pulse center (in OPL units)\n",
    "\n",
    "        Returns:\n",
    "            Normalized Gaussian value at t\n",
    "        \"\"\"\n",
    "        return self.normalization * dr.exp(-0.5 * (t / self.width_opl) ** 2)\n",
    "\n",
    "    def sample(self, xi: mi.Float):\n",
    "        \"\"\"\n",
    "        Sample a time offset from the Gaussian distribution using inverse CDF.\n",
    "\n",
    "        Args:\n",
    "            xi: Uniform random value in [0, 1]\n",
    "\n",
    "        Returns:\n",
    "            Tuple of (sampled_time, weight) where weight is always 1.0\n",
    "            for importance sampling\n",
    "        \"\"\"\n",
    "        # TODO: Implement inverse CDF sampling using the inverse error function\n",
    "        # Hint: For a Gaussian, the inverse CDF is: μ + σ × √2 × erfinv(2ξ - 1)\n",
    "        # Use dr.erfinv() for the inverse error function\n",
    "        return self.width_opl * dr.sqrt(2) * dr.erfinv(2 * xi - 1)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad9ea43c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integral: 0.9990 (should be ~1.0)\n",
      "Sample mean: -0.0003 (should be ~0.0)\n",
      "Sample std: 0.0499 (should be ~0.0500)\n"
     ]
    }
   ],
   "source": [
    "# Test that the pulse integrates to 1\n",
    "pulse = GaussianPulse(width_opl=0.05)\n",
    "t = dr.linspace(mi.Float, -0.5, 0.5, 1000)\n",
    "dt = 1.0 / 1000\n",
    "integral = dr.sum(pulse.eval(t)) * dt\n",
    "print(f\"Integral: {integral[0]:.4f} (should be ~1.0)\")\n",
    "\n",
    "# Test sampling\n",
    "samples = [pulse.sample(dr.opaque(mi.Float, np.random.random()))[0] for _ in range(10000)]\n",
    "print(f\"Sample mean: {np.mean(samples):.4f} (should be ~0.0)\")\n",
    "print(f\"Sample std: {np.std(samples):.4f} (should be ~{pulse.width_opl:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81f9bb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleIntegrator(mi.SamplingIntegrator):\n",
    "    def __init__(self, sample_lights = True, sample_bsdf=True, max_depth=5, props=mi.Properties()):\n",
    "        super().__init__(props)\n",
    "        self.sample_lights = sample_lights\n",
    "        self.sample_bsdf = sample_bsdf\n",
    "        self.max_depth = max_depth\n",
    "\n",
    "    def sample(self, scene, sampler, ray, medium=None, active=True):\n",
    "        # Intersect ray with scene\n",
    "        beta = mi.Color3f(1.0)\n",
    "        result = mi.Color3f(0.0)\n",
    "        specular = dr.auto.ad.Bool(True)\n",
    "        \n",
    "        for depth in range(self.max_depth):\n",
    "            si = scene.ray_intersect(ray, active)\n",
    "\n",
    "            active &= si.is_valid()\n",
    "\n",
    "            if not dr.any(active):\n",
    "                # Add environment contribution for rays that didn't hit anything\n",
    "                env_mask = active & (specular | ~dr.auto.ad.Bool(self.sample_lights))\n",
    "                result[env_mask] += beta * scene.environment().eval(si, env_mask)\n",
    "                break\n",
    "\n",
    "            # Add emitter contribution if we hit a light and either sampling specular or not sampling lights\n",
    "            emitter_mask = active & (specular | ~dr.auto.ad.Bool(self.sample_lights))\n",
    "            result[emitter_mask] += beta * si.emitter(scene).eval(si, emitter_mask)\n",
    "\n",
    "            # Sample direct illumination from light sources\n",
    "            ctx = mi.BSDFContext()\n",
    "            bsdf = si.bsdf()\n",
    "\n",
    "            if self.sample_lights:\n",
    "                # Sample a light source\n",
    "                ds, emitter_weight = scene.sample_emitter_direction(\n",
    "                    si, sampler.next_2d(), True, active\n",
    "                )\n",
    "\n",
    "                active_light = active & (ds.pdf > 0)\n",
    "\n",
    "                if dr.any(active_light):\n",
    "                    # Evaluate BSDF\n",
    "                    bsdf_val = bsdf.eval(ctx, si, si.to_local(ds.d), active_light)\n",
    "\n",
    "                    # Visibility test\n",
    "                    ray_shadow = si.spawn_ray_to(ds.p)\n",
    "                    visible = ~scene.ray_test(ray_shadow, active_light)\n",
    "\n",
    "                    # Accumulate contribution\n",
    "                    result[active_light & visible] += (\n",
    "                        beta * bsdf_val * emitter_weight\n",
    "                    )\n",
    "            \n",
    "            # Sample BSDF to get new direction\n",
    "            if (self.sample_bsdf):\n",
    "                bsdf_sample, bsdf_weight = bsdf.sample(\n",
    "                    ctx, si, sampler.next_1d(), sampler.next_2d(), active\n",
    "                )\n",
    "\n",
    "                active_bsdf = active & dr.any(bsdf_weight != 0)\n",
    "\n",
    "                # Update beta with mask\n",
    "                beta[active_bsdf] = beta * bsdf_weight\n",
    "\n",
    "                # Spawn new ray with mask\n",
    "                ray[active_bsdf] = si.spawn_ray(si.to_world(bsdf_sample.wo))\n",
    "\n",
    "                # Update specular flag with mask\n",
    "                specular[active_bsdf] = mi.has_flag(bsdf_sample.sampled_type, mi.BSDFFlags.Delta)\n",
    "                \n",
    "                # Update active mask - continue only where BSDF sampling succeeded\n",
    "                active &= active_bsdf\n",
    "            else:\n",
    "                # uniformly sample hemisphere\n",
    "                wi = sampler.next_2d()\n",
    "                local_dir = mi.warp.square_to_uniform_hemisphere(wi)\n",
    "                bsdf_val = bsdf.eval(ctx, si, local_dir, active)\n",
    "                pdf = mi.warp.square_to_uniform_hemisphere_pdf(local_dir)\n",
    "                bsdf_weight = bsdf_val * dr.abs(dr.dot(si.n, si.to_world(local_dir))) / pdf\n",
    "                \n",
    "                # Update with mask\n",
    "                beta[active] = beta * bsdf_weight\n",
    "                ray[active] = si.spawn_ray(si.to_world(local_dir))\n",
    "                specular[active] = dr.auto.Bool(False)\n",
    "\n",
    "        return result, active, []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97af95d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "def visualize_transient(transient_data, start_opl, bin_width_opl):\n",
    "    \"\"\"Create an animation of light propagating through the scene.\"\"\"\n",
    "    data = np.array(transient_data)\n",
    "    print(f\"Data shape: {data.shape}\")  # Should be (H, W, 3, T)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Normalize data\n",
    "    vmax = np.percentile(data, 99)\n",
    "    \n",
    "    # Get first RGB frame: shape (H, W, 3)\n",
    "    first_frame = np.clip(data[:, :, :, 0], 0, vmax) / vmax\n",
    "    im = ax.imshow(first_frame)\n",
    "    \n",
    "    # Create title as text object for proper blitting\n",
    "    title = ax.text(0.5, 1.05, '', transform=ax.transAxes, \n",
    "                    ha='center', fontsize=12)\n",
    "\n",
    "    def update(frame):\n",
    "        # Get RGB frame at time index 'frame': shape (H, W, 3)\n",
    "        frame_data = np.clip(data[:, :, :, frame], 0, vmax) / vmax\n",
    "        im.set_array(frame_data)\n",
    "        opl = start_opl + frame * bin_width_opl\n",
    "        t_ns = opl / 0.3  # Convert to nanoseconds (c ≈ 0.3 m/ns)\n",
    "        title.set_text(f'Frame {frame}/{data.shape[3]-1} | t = {t_ns:.2f} ns (OPL = {opl:.2f} m)')\n",
    "        return [im, title]\n",
    "\n",
    "    # Number of frames is the last dimension (temporal bins)\n",
    "    num_frames = data.shape[3]\n",
    "    print(f\"Creating animation with {num_frames} frames\")\n",
    "    \n",
    "    anim = FuncAnimation(fig, update, frames=num_frames, interval=50, blit=True)\n",
    "    return anim\n",
    "\n",
    "def plot_pixel_transient(transient_data, x, y, start_opl, bin_width_opl):\n",
    "    \"\"\"Plot temporal response at a single pixel.\"\"\"\n",
    "    data = np.array(transient_data)\n",
    "    \n",
    "    # data shape is (H, W, 3, T), get pixel at (y, x) across all time\n",
    "    response = data[y, x, :, :]  # Shape: (3, T)\n",
    "    # Convert to luminance\n",
    "    luminance = 0.2126 * response[0] + 0.7152 * response[1] + 0.0722 * response[2]\n",
    "\n",
    "    times = start_opl + np.arange(luminance.shape[0]) * bin_width_opl\n",
    "    times_ns = times / 0.3\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(times_ns, response[0], 'r-', alpha=0.7, label='Red')\n",
    "    plt.plot(times_ns, response[1], 'g-', alpha=0.7, label='Green')\n",
    "    plt.plot(times_ns, response[2], 'b-', alpha=0.7, label='Blue')\n",
    "    plt.plot(times_ns, luminance, 'k-', linewidth=2, label='Luminance')\n",
    "    plt.xlabel('Time (ns)')\n",
    "    plt.ylabel('Intensity')\n",
    "    plt.title(f'Transient at pixel ({x}, {y})')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdbcb422",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeGatedTransientPath(mi.SamplingIntegrator):\n",
    "    def __init__(self, props=mi.Properties()):\n",
    "        super().__init__(props)\n",
    "        self.max_depth = props.get('max_depth', 8)\n",
    "        self.pulse = GaussianPulse(width_opl=props.get('gaussian_stddev', 0.03))\n",
    "        self.camera_unwarp = props.get('camera_unwarp', False)\n",
    "        self.temporal_filter = props.get('temporal_filter', 'box')\n",
    "\n",
    "    @dr.syntax\n",
    "    def sample(self, scene, sampler, ray, target_time, medium=None, active=True):\n",
    "        \"\"\"\n",
    "        Sample paths and weight by temporal pulse.\n",
    "\n",
    "        Args:\n",
    "            scene: The scene to render\n",
    "            sampler: Random number generator\n",
    "            ray: Camera ray\n",
    "            target_time: The target time (in OPL units) we're rendering for\n",
    "            medium: Participating medium (optional)\n",
    "            active: Active ray mask\n",
    "\n",
    "        Returns:\n",
    "            (color, valid, aov) tuple\n",
    "        \"\"\"\n",
    "        result = mi.Color3f(0.0)\n",
    "        throughput = mi.Color3f(1.0)\n",
    "        ray = mi.Ray3f(ray)\n",
    "        active = mi.Bool(active)\n",
    "\n",
    "        # Track total path length (optical path length)\n",
    "        path_length = mi.Float(0.0)\n",
    "        depth = mi.UInt32(0)\n",
    "\n",
    "        while dr.hint(active, max_iterations=self.max_depth, label=\"Path\"):\n",
    "            si = scene.ray_intersect(ray, active)\n",
    "            active &= si.is_valid()\n",
    "\n",
    "            # Accumulate path length\n",
    "            path_length[active] += si.t\n",
    "\n",
    "            # Get BSDF and context\n",
    "            ctx = mi.BSDFContext()\n",
    "            bsdf = si.bsdf()\n",
    "\n",
    "            # Emitter contribution (only for directly hit emitters)\n",
    "            emitter = si.emitter(scene)\n",
    "            emitter_contrib = dr.select(\n",
    "                emitter != None,\n",
    "                emitter.eval(si, active),\n",
    "                mi.Color3f(0.0)\n",
    "            )\n",
    "            result[active] += throughput * emitter_contrib\n",
    "\n",
    "            # Sample direct illumination from light sources (NEE)\n",
    "            ds, emitter_weight = scene.sample_emitter_direction(\n",
    "                si, sampler.next_2d(), True, active\n",
    "            )\n",
    "\n",
    "            active_light = active & (ds.pdf > 0)\n",
    "\n",
    "            # Remove the if dr.any() check - just use masking\n",
    "            # Evaluate BSDF\n",
    "            bsdf_val = bsdf.eval(ctx, si, si.to_local(ds.d), active_light)\n",
    "\n",
    "            # Visibility test\n",
    "            ray_shadow = si.spawn_ray_to(ds.p)\n",
    "            visible = ~scene.ray_test(ray_shadow, active_light)\n",
    "\n",
    "            # Compute time-gated weight\n",
    "            distance_to_light = dr.norm(ds.p - si.p)\n",
    "            total_opl = path_length + distance_to_light\n",
    "            shifted_time = target_time - total_opl\n",
    "            pulse_weight = self.pulse.eval(shifted_time)\n",
    "\n",
    "            # Accumulate contribution (masking handles inactive lanes)\n",
    "            result[active_light & visible] += (\n",
    "                throughput * bsdf_val * emitter_weight * pulse_weight\n",
    "            )\n",
    "\n",
    "            # Sample BSDF to get new direction\n",
    "            bsdf_sample, bsdf_weight = bsdf.sample(\n",
    "                ctx, si, sampler.next_1d(), sampler.next_2d(), active\n",
    "            )\n",
    "\n",
    "            active_bsdf = active & dr.any(bsdf_weight != 0)\n",
    "\n",
    "            # Update throughput with mask\n",
    "            throughput[active_bsdf] = throughput * bsdf_weight\n",
    "\n",
    "            # Spawn new ray with mask\n",
    "            ray[active_bsdf] = si.spawn_ray(si.to_world(bsdf_sample.wo))\n",
    "            \n",
    "            # Update depth\n",
    "            depth[si.is_valid()] += 1\n",
    "            \n",
    "            # Update active mask - continue only where BSDF sampling succeeded\n",
    "            active &= active_bsdf\n",
    "\n",
    "        return result, mi.Bool(True), []\n",
    "mi.register_integrator('transient_path', lambda props: TimeGatedTransientPath(props))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b618bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendering bin 1/300, target_time=3.510\n",
      "Rendering bin 2/300, target_time=3.530\n",
      "Rendering bin 3/300, target_time=3.550\n",
      "Rendering bin 4/300, target_time=3.570\n",
      "Rendering bin 5/300, target_time=3.590\n",
      "Rendering bin 6/300, target_time=3.610\n",
      "Rendering bin 7/300, target_time=3.630\n",
      "Rendering bin 8/300, target_time=3.650\n",
      "Rendering bin 9/300, target_time=3.670\n",
      "Rendering bin 10/300, target_time=3.690\n",
      "Rendering bin 11/300, target_time=3.710\n",
      "Rendering bin 12/300, target_time=3.730\n",
      "Rendering bin 13/300, target_time=3.750\n",
      "Rendering bin 14/300, target_time=3.770\n",
      "Rendering bin 15/300, target_time=3.790\n",
      "Rendering bin 16/300, target_time=3.810\n",
      "Rendering bin 17/300, target_time=3.830\n",
      "Rendering bin 18/300, target_time=3.850\n",
      "Rendering bin 19/300, target_time=3.870\n",
      "Rendering bin 20/300, target_time=3.890\n",
      "Rendering bin 21/300, target_time=3.910\n",
      "Rendering bin 22/300, target_time=3.930\n",
      "Rendering bin 23/300, target_time=3.950\n",
      "Rendering bin 24/300, target_time=3.970\n",
      "Rendering bin 25/300, target_time=3.990\n",
      "Rendering bin 26/300, target_time=4.010\n",
      "Rendering bin 27/300, target_time=4.030\n",
      "Rendering bin 28/300, target_time=4.050\n",
      "Rendering bin 29/300, target_time=4.070\n",
      "Rendering bin 30/300, target_time=4.090\n",
      "Rendering bin 31/300, target_time=4.110\n",
      "Rendering bin 32/300, target_time=4.130\n",
      "Rendering bin 33/300, target_time=4.150\n",
      "Rendering bin 34/300, target_time=4.170\n",
      "Rendering bin 35/300, target_time=4.190\n",
      "Rendering bin 36/300, target_time=4.210\n",
      "Rendering bin 37/300, target_time=4.230\n",
      "Rendering bin 38/300, target_time=4.250\n",
      "Rendering bin 39/300, target_time=4.270\n",
      "Rendering bin 40/300, target_time=4.290\n",
      "Rendering bin 41/300, target_time=4.310\n",
      "Rendering bin 42/300, target_time=4.330\n",
      "Rendering bin 43/300, target_time=4.350\n",
      "Rendering bin 44/300, target_time=4.370\n",
      "Rendering bin 45/300, target_time=4.390\n",
      "Rendering bin 46/300, target_time=4.410\n",
      "Rendering bin 47/300, target_time=4.430\n",
      "Rendering bin 48/300, target_time=4.450\n",
      "Rendering bin 49/300, target_time=4.470\n",
      "Rendering bin 50/300, target_time=4.490\n",
      "Rendering bin 51/300, target_time=4.510\n",
      "Rendering bin 52/300, target_time=4.530\n",
      "Rendering bin 53/300, target_time=4.550\n",
      "Rendering bin 54/300, target_time=4.570\n",
      "Rendering bin 55/300, target_time=4.590\n",
      "Rendering bin 56/300, target_time=4.610\n",
      "Rendering bin 57/300, target_time=4.630\n",
      "Rendering bin 58/300, target_time=4.650\n",
      "Rendering bin 59/300, target_time=4.670\n",
      "Rendering bin 60/300, target_time=4.690\n",
      "Rendering bin 61/300, target_time=4.710\n",
      "Rendering bin 62/300, target_time=4.730\n",
      "Rendering bin 63/300, target_time=4.750\n",
      "Rendering bin 64/300, target_time=4.770\n",
      "Rendering bin 65/300, target_time=4.790\n",
      "Rendering bin 66/300, target_time=4.810\n",
      "Rendering bin 67/300, target_time=4.830\n",
      "Rendering bin 68/300, target_time=4.850\n",
      "Rendering bin 69/300, target_time=4.870\n",
      "Rendering bin 70/300, target_time=4.890\n",
      "Rendering bin 71/300, target_time=4.910\n",
      "Rendering bin 72/300, target_time=4.930\n",
      "Rendering bin 73/300, target_time=4.950\n",
      "Rendering bin 74/300, target_time=4.970\n",
      "Rendering bin 75/300, target_time=4.990\n",
      "Rendering bin 76/300, target_time=5.010\n",
      "Rendering bin 77/300, target_time=5.030\n",
      "Rendering bin 78/300, target_time=5.050\n",
      "Rendering bin 79/300, target_time=5.070\n",
      "Rendering bin 80/300, target_time=5.090\n",
      "Rendering bin 81/300, target_time=5.110\n",
      "Rendering bin 82/300, target_time=5.130\n",
      "Rendering bin 83/300, target_time=5.150\n",
      "Rendering bin 84/300, target_time=5.170\n",
      "Rendering bin 85/300, target_time=5.190\n",
      "Rendering bin 86/300, target_time=5.210\n",
      "Rendering bin 87/300, target_time=5.230\n",
      "Rendering bin 88/300, target_time=5.250\n",
      "Rendering bin 89/300, target_time=5.270\n",
      "Rendering bin 90/300, target_time=5.290\n",
      "Rendering bin 91/300, target_time=5.310\n",
      "Rendering bin 92/300, target_time=5.330\n",
      "Rendering bin 93/300, target_time=5.350\n",
      "Rendering bin 94/300, target_time=5.370\n",
      "Rendering bin 95/300, target_time=5.390\n",
      "Rendering bin 96/300, target_time=5.410\n",
      "Rendering bin 97/300, target_time=5.430\n",
      "Rendering bin 98/300, target_time=5.450\n",
      "Rendering bin 99/300, target_time=5.470\n",
      "Rendering bin 100/300, target_time=5.490\n",
      "Rendering bin 101/300, target_time=5.510\n",
      "Rendering bin 102/300, target_time=5.530\n",
      "Rendering bin 103/300, target_time=5.550\n",
      "Rendering bin 104/300, target_time=5.570\n",
      "Rendering bin 105/300, target_time=5.590\n",
      "Rendering bin 106/300, target_time=5.610\n",
      "Rendering bin 107/300, target_time=5.630\n",
      "Rendering bin 108/300, target_time=5.650\n",
      "Rendering bin 109/300, target_time=5.670\n",
      "Rendering bin 110/300, target_time=5.690\n",
      "Rendering bin 111/300, target_time=5.710\n",
      "Rendering bin 112/300, target_time=5.730\n",
      "Rendering bin 113/300, target_time=5.750\n",
      "Rendering bin 114/300, target_time=5.770\n",
      "Rendering bin 115/300, target_time=5.790\n",
      "Rendering bin 116/300, target_time=5.810\n",
      "Rendering bin 117/300, target_time=5.830\n",
      "Rendering bin 118/300, target_time=5.850\n",
      "Rendering bin 119/300, target_time=5.870\n",
      "Rendering bin 120/300, target_time=5.890\n",
      "Rendering bin 121/300, target_time=5.910\n",
      "Rendering bin 122/300, target_time=5.930\n",
      "Rendering bin 123/300, target_time=5.950\n",
      "Rendering bin 124/300, target_time=5.970\n",
      "Rendering bin 125/300, target_time=5.990\n",
      "Rendering bin 126/300, target_time=6.010\n",
      "Rendering bin 127/300, target_time=6.030\n",
      "Rendering bin 128/300, target_time=6.050\n",
      "Rendering bin 129/300, target_time=6.070\n",
      "Rendering bin 130/300, target_time=6.090\n",
      "Rendering bin 131/300, target_time=6.110\n",
      "Rendering bin 132/300, target_time=6.130\n",
      "Rendering bin 133/300, target_time=6.150\n",
      "Rendering bin 134/300, target_time=6.170\n",
      "Rendering bin 135/300, target_time=6.190\n",
      "Rendering bin 136/300, target_time=6.210\n",
      "Rendering bin 137/300, target_time=6.230\n",
      "Rendering bin 138/300, target_time=6.250\n",
      "Rendering bin 139/300, target_time=6.270\n",
      "Rendering bin 140/300, target_time=6.290\n",
      "Rendering bin 141/300, target_time=6.310\n",
      "Rendering bin 142/300, target_time=6.330\n",
      "Rendering bin 143/300, target_time=6.350\n",
      "Rendering bin 144/300, target_time=6.370\n",
      "Rendering bin 145/300, target_time=6.390\n",
      "Rendering bin 146/300, target_time=6.410\n",
      "Rendering bin 147/300, target_time=6.430\n",
      "Rendering bin 148/300, target_time=6.450\n",
      "Rendering bin 149/300, target_time=6.470\n",
      "Rendering bin 150/300, target_time=6.490\n",
      "Rendering bin 151/300, target_time=6.510\n",
      "Rendering bin 152/300, target_time=6.530\n",
      "Rendering bin 153/300, target_time=6.550\n",
      "Rendering bin 154/300, target_time=6.570\n",
      "Rendering bin 155/300, target_time=6.590\n",
      "Rendering bin 156/300, target_time=6.610\n",
      "Rendering bin 157/300, target_time=6.630\n",
      "Rendering bin 158/300, target_time=6.650\n",
      "Rendering bin 159/300, target_time=6.670\n",
      "Rendering bin 160/300, target_time=6.690\n",
      "Rendering bin 161/300, target_time=6.710\n",
      "Rendering bin 162/300, target_time=6.730\n",
      "Rendering bin 163/300, target_time=6.750\n",
      "Rendering bin 164/300, target_time=6.770\n",
      "Rendering bin 165/300, target_time=6.790\n",
      "Rendering bin 166/300, target_time=6.810\n",
      "Rendering bin 167/300, target_time=6.830\n",
      "Rendering bin 168/300, target_time=6.850\n",
      "Rendering bin 169/300, target_time=6.870\n",
      "Rendering bin 170/300, target_time=6.890\n",
      "Rendering bin 171/300, target_time=6.910\n",
      "Rendering bin 172/300, target_time=6.930\n",
      "Rendering bin 173/300, target_time=6.950\n",
      "Rendering bin 174/300, target_time=6.970\n",
      "Rendering bin 175/300, target_time=6.990\n",
      "Rendering bin 176/300, target_time=7.010\n",
      "Rendering bin 177/300, target_time=7.030\n",
      "Rendering bin 178/300, target_time=7.050\n",
      "Rendering bin 179/300, target_time=7.070\n",
      "Rendering bin 180/300, target_time=7.090\n",
      "Rendering bin 181/300, target_time=7.110\n",
      "Rendering bin 182/300, target_time=7.130\n",
      "Rendering bin 183/300, target_time=7.150\n",
      "Rendering bin 184/300, target_time=7.170\n",
      "Rendering bin 185/300, target_time=7.190\n",
      "Rendering bin 186/300, target_time=7.210\n",
      "Rendering bin 187/300, target_time=7.230\n",
      "Rendering bin 188/300, target_time=7.250\n",
      "Rendering bin 189/300, target_time=7.270\n",
      "Rendering bin 190/300, target_time=7.290\n",
      "Rendering bin 191/300, target_time=7.310\n",
      "Rendering bin 192/300, target_time=7.330\n",
      "Rendering bin 193/300, target_time=7.350\n",
      "Rendering bin 194/300, target_time=7.370\n",
      "Rendering bin 195/300, target_time=7.390\n",
      "Rendering bin 196/300, target_time=7.410\n",
      "Rendering bin 197/300, target_time=7.430\n",
      "Rendering bin 198/300, target_time=7.450\n",
      "Rendering bin 199/300, target_time=7.470\n",
      "Rendering bin 200/300, target_time=7.490\n",
      "Rendering bin 201/300, target_time=7.510\n",
      "Rendering bin 202/300, target_time=7.530\n",
      "Rendering bin 203/300, target_time=7.550\n",
      "Rendering bin 204/300, target_time=7.570\n",
      "Rendering bin 205/300, target_time=7.590\n",
      "Rendering bin 206/300, target_time=7.610\n",
      "Rendering bin 207/300, target_time=7.630\n",
      "Rendering bin 208/300, target_time=7.650\n",
      "Rendering bin 209/300, target_time=7.670\n",
      "Rendering bin 210/300, target_time=7.690\n",
      "Rendering bin 211/300, target_time=7.710\n",
      "Rendering bin 212/300, target_time=7.730\n",
      "Rendering bin 213/300, target_time=7.750\n",
      "Rendering bin 214/300, target_time=7.770\n",
      "Rendering bin 215/300, target_time=7.790\n",
      "Rendering bin 216/300, target_time=7.810\n",
      "Rendering bin 217/300, target_time=7.830\n",
      "Rendering bin 218/300, target_time=7.850\n",
      "Rendering bin 219/300, target_time=7.870\n",
      "Rendering bin 220/300, target_time=7.890\n",
      "Rendering bin 221/300, target_time=7.910\n",
      "Rendering bin 222/300, target_time=7.930\n",
      "Rendering bin 223/300, target_time=7.950\n",
      "Rendering bin 224/300, target_time=7.970\n",
      "Rendering bin 225/300, target_time=7.990\n",
      "Rendering bin 226/300, target_time=8.010\n",
      "Rendering bin 227/300, target_time=8.030\n",
      "Rendering bin 228/300, target_time=8.050\n",
      "Rendering bin 229/300, target_time=8.070\n",
      "Rendering bin 230/300, target_time=8.090\n",
      "Rendering bin 231/300, target_time=8.110\n",
      "Rendering bin 232/300, target_time=8.130\n",
      "Rendering bin 233/300, target_time=8.150\n",
      "Rendering bin 234/300, target_time=8.170\n",
      "Rendering bin 235/300, target_time=8.190\n",
      "Rendering bin 236/300, target_time=8.210\n",
      "Rendering bin 237/300, target_time=8.230\n",
      "Rendering bin 238/300, target_time=8.250\n",
      "Rendering bin 239/300, target_time=8.270\n",
      "Rendering bin 240/300, target_time=8.290\n",
      "Rendering bin 241/300, target_time=8.310\n",
      "Rendering bin 242/300, target_time=8.330\n",
      "Rendering bin 243/300, target_time=8.350\n",
      "Rendering bin 244/300, target_time=8.370\n",
      "Rendering bin 245/300, target_time=8.390\n",
      "Rendering bin 246/300, target_time=8.410\n",
      "Rendering bin 247/300, target_time=8.430\n",
      "Rendering bin 248/300, target_time=8.450\n",
      "Rendering bin 249/300, target_time=8.470\n",
      "Rendering bin 250/300, target_time=8.490\n",
      "Rendering bin 251/300, target_time=8.510\n",
      "Rendering bin 252/300, target_time=8.530\n",
      "Rendering bin 253/300, target_time=8.550\n",
      "Rendering bin 254/300, target_time=8.570\n",
      "Rendering bin 255/300, target_time=8.590\n",
      "Rendering bin 256/300, target_time=8.610\n",
      "Rendering bin 257/300, target_time=8.630\n",
      "Rendering bin 258/300, target_time=8.650\n",
      "Rendering bin 259/300, target_time=8.670\n",
      "Rendering bin 260/300, target_time=8.690\n",
      "Rendering bin 261/300, target_time=8.710\n",
      "Rendering bin 262/300, target_time=8.730\n",
      "Rendering bin 263/300, target_time=8.750\n",
      "Rendering bin 264/300, target_time=8.770\n",
      "Rendering bin 265/300, target_time=8.790\n",
      "Rendering bin 266/300, target_time=8.810\n",
      "Rendering bin 267/300, target_time=8.830\n",
      "Rendering bin 268/300, target_time=8.850\n",
      "Rendering bin 269/300, target_time=8.870\n",
      "Rendering bin 270/300, target_time=8.890\n",
      "Rendering bin 271/300, target_time=8.910\n",
      "Rendering bin 272/300, target_time=8.930\n",
      "Rendering bin 273/300, target_time=8.950\n",
      "Rendering bin 274/300, target_time=8.970\n",
      "Rendering bin 275/300, target_time=8.990\n",
      "Rendering bin 276/300, target_time=9.010\n",
      "Rendering bin 277/300, target_time=9.030\n",
      "Rendering bin 278/300, target_time=9.050\n",
      "Rendering bin 279/300, target_time=9.070\n",
      "Rendering bin 280/300, target_time=9.090\n",
      "Rendering bin 281/300, target_time=9.110\n",
      "Rendering bin 282/300, target_time=9.130\n",
      "Rendering bin 283/300, target_time=9.150\n",
      "Rendering bin 284/300, target_time=9.170\n",
      "Rendering bin 285/300, target_time=9.190\n",
      "Rendering bin 286/300, target_time=9.210\n",
      "Rendering bin 287/300, target_time=9.230\n",
      "Rendering bin 288/300, target_time=9.250\n",
      "Rendering bin 289/300, target_time=9.270\n",
      "Rendering bin 290/300, target_time=9.290\n",
      "Rendering bin 291/300, target_time=9.310\n",
      "Rendering bin 292/300, target_time=9.330\n",
      "Rendering bin 293/300, target_time=9.350\n",
      "Rendering bin 294/300, target_time=9.370\n",
      "Rendering bin 295/300, target_time=9.390\n",
      "Rendering bin 296/300, target_time=9.410\n",
      "Rendering bin 297/300, target_time=9.430\n",
      "Rendering bin 298/300, target_time=9.450\n",
      "Rendering bin 299/300, target_time=9.470\n",
      "Rendering bin 300/300, target_time=9.490\n"
     ]
    }
   ],
   "source": [
    "def render_at_time(scene, integrator, target_time, spp=64):\n",
    "    \"\"\"Render a single time slice by calling integrator with target_time.\"\"\"\n",
    "    sensor = scene.sensors()[0]\n",
    "    film = sensor.film()\n",
    "    sampler = sensor.sampler()\n",
    "    \n",
    "    film_size = film.crop_size()\n",
    "    total_sample_count = dr.prod(film_size) * spp\n",
    "    \n",
    "    sampler.set_sample_count(spp)\n",
    "    sampler.seed(0, total_sample_count)\n",
    "    \n",
    "    # Generate sample positions\n",
    "    idx = dr.arange(mi.UInt32, total_sample_count)\n",
    "    \n",
    "    # Determine pixel coordinates\n",
    "    idx_pixel = idx // spp\n",
    "    pos_x = idx_pixel % film_size[0]\n",
    "    pos_y = idx_pixel // film_size[0]\n",
    "    \n",
    "    # Add sub-pixel jitter\n",
    "    pixel_center = mi.Vector2f(mi.Float(pos_x), mi.Float(pos_y)) + sampler.next_2d()\n",
    "    \n",
    "    # Normalized coordinates [0, 1]\n",
    "    scale = mi.Vector2f(1.0 / film_size[0], 1.0 / film_size[1])\n",
    "    normalized_pos = pixel_center * scale\n",
    "    \n",
    "    # Sample camera rays\n",
    "    ray, ray_weight = sensor.sample_ray_differential(\n",
    "        time=0.0,\n",
    "        sample1=sampler.next_1d(),\n",
    "        sample2=normalized_pos,\n",
    "        sample3=0.0\n",
    "    )\n",
    "    \n",
    "    # Call integrator with target_time\n",
    "    result, valid, _ = integrator.sample(scene, sampler, ray, target_time)\n",
    "    \n",
    "    # Scale by ray_weight\n",
    "    result = result * ray_weight\n",
    "    \n",
    "    # Reshape to (height, width, spp, 3) then average over spp dimension\n",
    "    result_reshaped = dr.reshape(mi.TensorXf, result, \n",
    "                                 shape=(film_size[1], film_size[0], spp, 3))\n",
    "    \n",
    "    # Average samples per pixel (mean along axis 2 which is the spp dimension)\n",
    "    result_image = dr.mean(result_reshaped, axis=2)\n",
    "    \n",
    "    return result_image\n",
    "    \n",
    "def render_transient(scene, integrator, film_config, spp=64):\n",
    "    \"\"\"Render transient by sampling different target times.\"\"\"\n",
    "    num_bins = film_config['temporal_bins']\n",
    "    start_opl = film_config['start_opl']\n",
    "    bin_width = film_config['bin_width_opl']\n",
    "\n",
    "    transient_data = []\n",
    "\n",
    "    for bin_idx in range(num_bins):\n",
    "        # Target time for this bin (can add jitter for anti-aliasing)\n",
    "        target_time = start_opl + (bin_idx + 0.5) * bin_width\n",
    "\n",
    "        print(f\"Rendering bin {bin_idx+1}/{num_bins}, target_time={target_time:.3f}\")\n",
    "        \n",
    "        # Render at this target time\n",
    "        image = render_at_time(scene, integrator, target_time, spp)\n",
    "        transient_data.append(np.array(image))\n",
    "\n",
    "    return np.stack(transient_data, axis=-1)\n",
    "\n",
    "# Load the transient Cornell Box scene\n",
    "scene_dict = cornell_box()\n",
    "scene = mi.load_dict(scene_dict)\n",
    "\n",
    "# Or use the steady-state version to test your path tracer first\n",
    "scene_dict_steady = cornell_box_steady_state()\n",
    "scene_steady = mi.load_dict(scene_dict_steady)\n",
    "props = mi.Properties()\n",
    "props['max_depth'] = 5\n",
    "props['gaussian_stddev'] = 0.03\n",
    "integrator = TimeGatedTransientPath(props)\n",
    "\n",
    "# Test with steady-state (all time bins sum together)\n",
    "# image = render_at_time(scene, integrator, target_time=3.0, spp=128)\n",
    "# plt.imshow(np.array(image))\n",
    "# plt.axis('off')\n",
    "# plt.title('Single time slice at t=3.0m')\n",
    "# plt.show()\n",
    "transient_data = render_transient(\n",
    "    scene, integrator,\n",
    "    film_config={\n",
    "        'temporal_bins': 300,\n",
    "        'start_opl': 3.5,\n",
    "        'bin_width_opl': 0.02\n",
    "    },\n",
    "    spp=128\n",
    ")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0007a72",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid shape (256, 256, 300) for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m anim = \u001b[43mvisualize_transient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransient_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_opl\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbin_width_opl\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.02\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m HTML(anim.to_jshtml())\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(transient_data.shape)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mvisualize_transient\u001b[39m\u001b[34m(transient_data, start_opl, bin_width_opl)\u001b[39m\n\u001b[32m     10\u001b[39m vmax = np.percentile(data, \u001b[32m99\u001b[39m)\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# im = ax.imshow(data[:, :, 0], cmap='hot', vmin=0, vmax=vmax)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m im = \u001b[43max\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mupdate\u001b[39m(frame):\n\u001b[32m     15\u001b[39m     im.set_array(data[:, :, frame])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mitsuba/lib/python3.11/site-packages/matplotlib/__init__.py:1524\u001b[39m, in \u001b[36m_preprocess_data.<locals>.inner\u001b[39m\u001b[34m(ax, data, *args, **kwargs)\u001b[39m\n\u001b[32m   1521\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minner\u001b[39m(ax, *args, data=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m   1523\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1524\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1525\u001b[39m \u001b[43m            \u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1526\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcbook\u001b[49m\u001b[43m.\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1527\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbook\u001b[49m\u001b[43m.\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1529\u001b[39m     bound = new_sig.bind(ax, *args, **kwargs)\n\u001b[32m   1530\u001b[39m     auto_label = (bound.arguments.get(label_namer)\n\u001b[32m   1531\u001b[39m                   \u001b[38;5;129;01mor\u001b[39;00m bound.kwargs.get(label_namer))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mitsuba/lib/python3.11/site-packages/matplotlib/axes/_axes.py:5982\u001b[39m, in \u001b[36mAxes.imshow\u001b[39m\u001b[34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, colorizer, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001b[39m\n\u001b[32m   5979\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m aspect \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   5980\u001b[39m     \u001b[38;5;28mself\u001b[39m.set_aspect(aspect)\n\u001b[32m-> \u001b[39m\u001b[32m5982\u001b[39m \u001b[43mim\u001b[49m\u001b[43m.\u001b[49m\u001b[43mset_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5983\u001b[39m im.set_alpha(alpha)\n\u001b[32m   5984\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m im.get_clip_path() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   5985\u001b[39m     \u001b[38;5;66;03m# image does not already have clipping set, clip to Axes patch\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mitsuba/lib/python3.11/site-packages/matplotlib/image.py:685\u001b[39m, in \u001b[36m_ImageBase.set_data\u001b[39m\u001b[34m(self, A)\u001b[39m\n\u001b[32m    683\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(A, PIL.Image.Image):\n\u001b[32m    684\u001b[39m     A = pil_to_array(A)  \u001b[38;5;66;03m# Needed e.g. to apply png palette.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m685\u001b[39m \u001b[38;5;28mself\u001b[39m._A = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_normalize_image_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    686\u001b[39m \u001b[38;5;28mself\u001b[39m._imcache = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    687\u001b[39m \u001b[38;5;28mself\u001b[39m.stale = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mitsuba/lib/python3.11/site-packages/matplotlib/image.py:653\u001b[39m, in \u001b[36m_ImageBase._normalize_image_array\u001b[39m\u001b[34m(A)\u001b[39m\n\u001b[32m    651\u001b[39m     A = A.squeeze(-\u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# If just (M, N, 1), assume scalar and apply colormap.\u001b[39;00m\n\u001b[32m    652\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (A.ndim == \u001b[32m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m A.ndim == \u001b[32m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m A.shape[-\u001b[32m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m [\u001b[32m3\u001b[39m, \u001b[32m4\u001b[39m]):\n\u001b[32m--> \u001b[39m\u001b[32m653\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mA.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for image data\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    654\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m A.ndim == \u001b[32m3\u001b[39m:\n\u001b[32m    655\u001b[39m     \u001b[38;5;66;03m# If the input data has values outside the valid range (after\u001b[39;00m\n\u001b[32m    656\u001b[39m     \u001b[38;5;66;03m# normalisation), we issue a warning and then clip X to the bounds\u001b[39;00m\n\u001b[32m    657\u001b[39m     \u001b[38;5;66;03m# - otherwise casting wraps extreme values, hiding outliers and\u001b[39;00m\n\u001b[32m    658\u001b[39m     \u001b[38;5;66;03m# making reliable interpretation impossible.\u001b[39;00m\n\u001b[32m    659\u001b[39m     high = \u001b[32m255\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m np.issubdtype(A.dtype, np.integer) \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m1\u001b[39m\n",
      "\u001b[31mTypeError\u001b[39m: Invalid shape (256, 256, 300) for image data"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "anim = visualize_transient(transient_data, start_opl=3.5, bin_width_opl=0.02)\n",
    "HTML(anim.to_jshtml())\n",
    "print(transient_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43d8a946",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'while' statement on line 20 (2160499640.py, line 30)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mreturn result, mi.Bool(True), []\u001b[39m\n    ^\n\u001b[31mIndentationError\u001b[39m\u001b[31m:\u001b[39m expected an indented block after 'while' statement on line 20\n"
     ]
    }
   ],
   "source": [
    "class TransientPath(mi.SamplingIntegrator):\n",
    "    \"\"\"\n",
    "    Transient path tracer that outputs to a TransientHDRFilm.\n",
    "\n",
    "    Unlike TimeGatedTransientPath which renders a single time slice,\n",
    "    this integrator adds contributions to all relevant time bins\n",
    "    based on path length.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, props=mi.Properties()):\n",
    "        super().__init__(props)\n",
    "        self.max_depth = props.get('max_depth', 8)\n",
    "        pulse_width = props.get('pulse_width_opl', 0.03)\n",
    "        self.pulse = GaussianPulse(width_opl=pulse_width)\n",
    "\n",
    "    @dr.syntax\n",
    "    def sample(self, scene, sampler, ray, medium=None, active=True):\n",
    "        # Initialize: throughput, path_length, depth, etc.\n",
    "        result = mi.Color3f(0.0)\n",
    "        throughput = mi.Color3f(1.0)\n",
    "        ray = mi.Ray3f(ray)\n",
    "        active = mi.Bool(active)\n",
    "        path_length = mi.Float(0.0)\n",
    "        depth = mi.UInt32(0)\n",
    "\n",
    "        while dr.hint(active, max_iterations=self.max_depth, label=\"Transient\"):\n",
    "            # 1. Ray intersection\n",
    "            si = scene.ray_intersect(ray, active)\n",
    "            active &= si.is_valid()\n",
    "\n",
    "            # 2. Accumulate path_length += si.t\n",
    "            path_length[active] += si.t\n",
    "\n",
    "            # 3. For NEE contribution:\n",
    "            #    - Compute total_path_length = path_length + distance_to_light\n",
    "            ctx = mi.BSDFContext()\n",
    "            bsdf = si.bsdf()\n",
    "\n",
    "            # Emitter contribution (only for directly hit emitters)\n",
    "            emitter = si.emitter(scene)\n",
    "            emitter_contrib = dr.select(\n",
    "                emitter != None,\n",
    "                emitter.eval(si, active),\n",
    "                mi.Color3f(0.0)\n",
    "            )\n",
    "            result[active] += throughput * emitter_contrib\n",
    "\n",
    "            # Sample direct illumination from light sources (NEE)\n",
    "            ds, emitter_weight = scene.sample_emitter_direction(\n",
    "                si, sampler.next_2d(), True, active\n",
    "            )\n",
    "\n",
    "            active_light = active & (ds.pdf > 0)\n",
    "\n",
    "            # Evaluate BSDF\n",
    "            bsdf_val = bsdf.eval(ctx, si, si.to_local(ds.d), active_light)\n",
    "\n",
    "            # Visibility test\n",
    "            ray_shadow = si.spawn_ray_to(ds.p)\n",
    "            visible = ~scene.ray_test(ray_shadow, active_light)\n",
    "\n",
    "            # Compute time-gated weight\n",
    "            distance_to_light = dr.norm(ds.p - si.p)\n",
    "            total_opl = path_length + distance_to_light\n",
    "            t_offset = self.pulse.sample(sampler.next_1d())\n",
    "            effective_opl = total_opl + t_offset\n",
    "\n",
    "            #    - Sample pulse offset: t_offset = pulse.sample(sampler.next_1d())\n",
    "            #    - effective_opl = total_path_length + t_offset\n",
    "            #    - Add contribution to transient film at effective_opl\n",
    "            pulse_weight = self.pulse.eval(effective_opl)\n",
    "            \n",
    "            # 4. BSDF sampling for next bounce\n",
    "\n",
    "        return result, mi.Bool(True), []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ea0e44",
   "metadata": {},
   "source": [
    "### AMCW Rendering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564fe7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase accumulated along the path\n",
    "c = 299792458.0  # Speed of light (m/s)\n",
    "frequency = 1e9  # Example frequency in Hz\n",
    "omega = 2 * np.pi * frequency  # Angular frequency\n",
    "phase = omega * (opl / c)\n",
    "\n",
    "# Phasor components\n",
    "phasor_real = radiance * dr.cos(phase)\n",
    "phasor_imag = radiance * dr.sin(phase)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mitsuba",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
